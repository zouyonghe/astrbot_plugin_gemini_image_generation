"""Google/Gemini å®˜æ–¹æ¥å£ä¾›åº”å•†å®ç°ã€‚"""

from __future__ import annotations

import asyncio
import base64
import tempfile
import time
from pathlib import Path
from typing import Any

import aiohttp
from astrbot.api import logger

from ..api_types import APIError, ApiRequestConfig
from ..tl_utils import save_base64_image
from .base import ProviderRequest


class GoogleProvider:
    name = "google"

    async def build_request(
        self, *, client: Any, config: ApiRequestConfig
    ) -> ProviderRequest:  # noqa: ANN401
        api_base = (config.api_base or "").rstrip("/")
        default_base = getattr(
            client,
            "GOOGLE_API_BASE",
            "https://generativelanguage.googleapis.com/v1beta",
        )

        if api_base:
            base = api_base
            logger.debug(f"ä½¿ç”¨è‡ªå®šä¹‰ API Base: {base}")
        else:
            base = default_base
            logger.debug(f"ä½¿ç”¨é»˜è®¤ API Base (google): {base}")

        # Google API éœ€è¦ç‰ˆæœ¬å‰ç¼€
        if not config.api_base or base == default_base:
            url = f"{base}/models/{config.model}:generateContent"
        elif not any(base.endswith(suffix) for suffix in ["/v1beta", "/v1"]):
            url = f"{base}/v1beta/models/{config.model}:generateContent"
            logger.debug("ä¸ºGoogle APIè‡ªåŠ¨æ·»åŠ v1betaå‰ç¼€")
        else:
            url = f"{base}/models/{config.model}:generateContent"
            logger.debug("ä½¿ç”¨å·²åŒ…å«ç‰ˆæœ¬å‰ç¼€çš„Google APIåœ°å€")

        payload = await self._prepare_payload(client=client, config=config)
        headers = {
            "x-goog-api-key": config.api_key or "",
            "Content-Type": "application/json",
        }
        logger.debug(f"æ™ºèƒ½æ„å»ºAPI URL: {url}")
        return ProviderRequest(url=url, headers=headers, payload=payload)

    async def parse_response(
        self,
        *,
        client: Any,
        response_data: dict[str, Any],
        session: aiohttp.ClientSession,
        api_base: str | None = None,
    ) -> tuple[list[str], list[str], str | None, str | None]:  # noqa: ANN401
        # è§£æé€»è¾‘åœ¨æœ¬æ–‡ä»¶å†…å®ç°ï¼Œä½†ä¼šå¤ç”¨ client ä¸Šçš„é€šç”¨èƒ½åŠ›ã€‚
        return await self._parse_gresponse(
            client=client, response_data=response_data, session=session
        )

    async def _prepare_payload(
        self, *, client: Any, config: ApiRequestConfig
    ) -> dict[str, Any]:  # noqa: ANN401
        logger.debug(
            "[google] æ„å»º payload: model=%s refs=%s force_b64=%s aspect=%s res=%s",
            config.model,
            len(config.reference_images or []),
            config.image_input_mode,
            config.aspect_ratio,
            config.resolution,
        )
        parts: list[dict[str, Any]] = [{"text": config.prompt}]

        added_refs = 0
        fail_reasons: list[str] = []
        total_ref_count = len(config.reference_images or [])
        # å®é™…å¤„ç†çš„å‚è€ƒå›¾æ•°é‡å— [:14] é™åˆ¶
        processed_ref_count = min(total_ref_count, 14)
        total_start = time.perf_counter()
        if total_ref_count > 0:
            if total_ref_count > processed_ref_count:
                logger.info(
                    f"ğŸ“ å¼€å§‹å¤„ç† {processed_ref_count} å¼ å‚è€ƒå›¾ç‰‡ (å…±é…ç½® {total_ref_count} å¼ ï¼Œæœ€å¤šå¤„ç† 14 å¼ )..."
                )
            else:
                logger.info(f"ğŸ“ å¼€å§‹å¤„ç† {processed_ref_count} å¼ å‚è€ƒå›¾ç‰‡...")

        if config.reference_images:
            for idx, image_input in enumerate(config.reference_images[:14]):
                image_str = str(image_input).strip()
                logger.debug(
                    "[google] å¤„ç†å‚è€ƒå›¾ idx=%s type=%s preview=%s",
                    idx,
                    type(image_input),
                    image_str[:120],
                )

                mime_type, data, is_url = await client._process_reference_image(
                    image_input, idx, config.image_input_mode
                )

                if not data:
                    if is_url:
                        parts.append({"fileData": {"fileUri": image_str}})
                        added_refs += 1
                        logger.info(
                            "[google] URL ä¸‹è½½å¤±è´¥ï¼Œæ”¹ç”¨ fileData ä¼ è¾“ idx=%s url=%s",
                            idx,
                            image_str[:80],
                        )
                        continue

                    data = image_str
                    mime_type = client._ensure_mime_type(mime_type)
                    logger.debug(
                        "[google] è½¬æ¢å¤±è´¥ï¼Œç›´æ¥é€ä¼ åŸå§‹æ•°æ® idx=%s preview=%s",
                        idx,
                        image_str[:80],
                    )

                validated_data, is_valid = client._validate_b64_with_fallback(
                    data, context="google-inline"
                )

                if not is_valid and is_url:
                    parts.append({"fileData": {"fileUri": image_str}})
                    added_refs += 1
                    logger.info(
                        "[google] base64 æ ¡éªŒå¤±è´¥ï¼Œæ”¹ç”¨ fileData ä¼ è¾“ idx=%s url=%s",
                        idx,
                        image_str[:80],
                    )
                    continue

                if not is_valid:
                    fail_reasons.append(f"å›¾ç‰‡{idx + 1}: base64æ ¡éªŒå¤±è´¥")
                    logger.debug(
                        "[google] å‚è€ƒå›¾ idx=%s base64 æ ¡éªŒå¤±è´¥ä¸”éURLï¼Œè·³è¿‡",
                        idx,
                    )
                    continue

                mime_type = client._ensure_mime_type(mime_type)
                size_kb = len(validated_data) // 1024 if validated_data else 0
                logger.info(
                    f"ğŸ“ å›¾ç‰‡ {idx + 1}/{processed_ref_count} å·²åŠ å…¥å‘é€è¯·æ±‚ ({mime_type}, {size_kb}KB)"
                )
                logger.debug(
                    "[google] æˆåŠŸå¤„ç†å‚è€ƒå›¾ idx=%s mime=%s size=%s",
                    idx,
                    mime_type,
                    len(validated_data) if validated_data else 0,
                )

                parts.append(
                    {"inlineData": {"mimeType": mime_type, "data": validated_data}}
                )
                added_refs += 1

        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        if processed_ref_count > 0:
            total_elapsed_ms = (time.perf_counter() - total_start) * 1000
            if added_refs > 0:
                logger.info(
                    f"ğŸ“ å‚è€ƒå›¾ç‰‡å¤„ç†å®Œæˆï¼š{added_refs}/{processed_ref_count} å¼ å·²æˆåŠŸåŠ å…¥å‘é€è¯·æ±‚ï¼Œè€—æ—¶ {total_elapsed_ms:.0f}ms"
                )
            else:
                logger.info(
                    f"ğŸ“ å‚è€ƒå›¾ç‰‡å¤„ç†å®Œæˆï¼š0/{processed_ref_count} å¼ æˆåŠŸï¼Œå…¨éƒ¨æœªèƒ½åŠ å…¥å‘é€è¯·æ±‚ï¼Œè€—æ—¶ {total_elapsed_ms:.0f}ms"
                )

        if config.reference_images and added_refs == 0:
            raise APIError(
                "å‚è€ƒå›¾å…¨éƒ¨æ— æ•ˆæˆ–ä¸‹è½½å¤±è´¥ï¼Œè¯·é‡æ–°å‘é€å›¾ç‰‡åé‡è¯•ã€‚"
                + (f" è¯¦æƒ…: {'; '.join(fail_reasons[:3])}" if fail_reasons else ""),
                None,
                "invalid_reference_image",
            )

        contents = [{"role": "user", "parts": parts}]

        generation_config: dict[str, Any] = {"responseModalities": ["TEXT", "IMAGE"]}

        modalities_map = {
            "TEXT": ["TEXT"],
            "IMAGE": ["IMAGE"],
            "TEXT_IMAGE": ["TEXT", "IMAGE"],
        }

        modalities = modalities_map.get(config.response_modalities, ["TEXT", "IMAGE"])

        if "IMAGE" not in modalities:
            logger.warning("é…ç½®ä¸­ç¼ºå°‘ IMAGE modalityï¼Œè‡ªåŠ¨æ·»åŠ ä»¥æ”¯æŒå›¾åƒç”Ÿæˆ")
            modalities.append("IMAGE")

        if "TEXT" not in modalities:
            logger.debug("æ·»åŠ  TEXT modality ä»¥æä¾›æ›´å¥½çš„å…¼å®¹æ€§")
            modalities.append("TEXT")

        generation_config["responseModalities"] = modalities
        logger.debug(f"å“åº”æ¨¡æ€: {modalities}")

        image_config: dict[str, Any] = {}

        _res_key = (config.resolution_param_name or "").strip()
        resolution_key = _res_key if _res_key else "image_size"
        _aspect_key = (config.aspect_ratio_param_name or "").strip()
        aspect_ratio_key = _aspect_key if _aspect_key else "aspect_ratio"

        if config.resolution:
            resolution = config.resolution.upper()

            if resolution in ["1K", "1024X1024"]:
                image_config[resolution_key] = "1K"
                logger.debug(f"è®¾ç½®å›¾åƒå°ºå¯¸: 1K (å‚æ•°å: {resolution_key})")
            elif resolution in ["2K", "2048X2048"]:
                image_config[resolution_key] = "2K"
                logger.debug(f"è®¾ç½®å›¾åƒå°ºå¯¸: 2K (å‚æ•°å: {resolution_key})")
            elif resolution in ["4K", "4096X4096"]:
                image_config[resolution_key] = "4K"
                logger.debug(f"è®¾ç½®å›¾åƒå°ºå¯¸: 4K (å‚æ•°å: {resolution_key})")
            else:
                image_config[resolution_key] = config.resolution
                logger.debug(
                    f"è®¾ç½®å›¾åƒå°ºå¯¸: {config.resolution} (å‚æ•°å: {resolution_key})"
                )

        if config.aspect_ratio:
            ratio = config.aspect_ratio.strip()
            image_config[aspect_ratio_key] = ratio
            logger.debug(f"è®¾ç½®é•¿å®½æ¯”: {ratio} (å‚æ•°å: {aspect_ratio_key})")

        if image_config:
            generation_config["image_config"] = image_config

        if config.temperature is not None:
            generation_config["temperature"] = config.temperature
        if config.seed is not None:
            generation_config["seed"] = config.seed
        if config.safety_settings:
            generation_config["safetySettings"] = config.safety_settings

        tools: list[dict[str, Any]] = []
        if config.enable_grounding:
            tools.append({"google_search": {}})

        payload: dict[str, Any] = {
            "contents": contents,
            "generationConfig": generation_config,
        }

        if tools:
            payload["tools"] = tools

        if "image_config" in generation_config:
            logger.debug(
                f"å®é™…å‘é€çš„ image_config: {generation_config['image_config']}"
            )

        return payload

    async def _parse_gresponse(
        self,
        *,
        client: Any,
        response_data: dict[str, Any],
        session: aiohttp.ClientSession,
    ) -> tuple[list[str], list[str], str | None, str | None]:  # noqa: ANN401
        parse_start = asyncio.get_event_loop().time()
        logger.debug("ğŸ” å¼€å§‹è§£æAPIå“åº”æ•°æ®...")

        image_urls: list[str] = []
        image_paths: list[str] = []
        text_chunks: list[str] = []
        thought_signature = None
        fallback_texts = client._collect_fallback_texts(response_data)

        if "candidates" not in response_data or not response_data["candidates"]:
            logger.warning(
                "Google å“åº”ç¼ºå°‘ candidates å­—æ®µï¼Œå°è¯•ä» fallback æ–‡æœ¬æå–å›¾åƒ"
            )
            appended = False
            if fallback_texts:
                appended = await client._append_images_from_texts(
                    fallback_texts, image_urls, image_paths
                )
            if appended and (image_urls or image_paths):
                text_content = (
                    " ".join(t.strip() for t in fallback_texts if t and t.strip())
                    or None
                )
                return image_urls, image_paths, text_content, thought_signature

            if "promptFeedback" in response_data:
                feedback = response_data["promptFeedback"]
                logger.warning(f"è¯·æ±‚è¢«é˜»æ­¢: {feedback}")
            else:
                logger.error("å“åº”ä¸­æ²¡æœ‰ candidatesï¼Œfallback æå–ä¹Ÿå¤±è´¥")
                logger.debug(f"å®Œæ•´å“åº”: {str(response_data)[:1000]}")
                logger.debug(f"fallback_texts: {fallback_texts}")
            return [], [], None, None

        candidates = response_data["candidates"]
        logger.debug(f"ğŸ“ æ‰¾åˆ° {len(candidates)} ä¸ªå€™é€‰ç»“æœ")

        for idx, candidate in enumerate(candidates):
            finish_reason = candidate.get("finishReason")
            if finish_reason in ["SAFETY", "RECITATION"]:
                logger.warning(f"å€™é€‰ {idx} ç”Ÿæˆè¢«é˜»æ­¢: {finish_reason}")
                continue

            content = candidate.get("content", {})
            parts = content.get("parts") or []
            logger.debug(f"ğŸ“‹ å€™é€‰ {idx} åŒ…å« {len(parts)} ä¸ªéƒ¨åˆ†")

            for i, part in enumerate(parts):
                try:
                    logger.debug(f"æ£€æŸ¥å€™é€‰ {idx} çš„ç¬¬ {i} ä¸ªpart: {list(part.keys())}")

                    if "thoughtSignature" in part and not thought_signature:
                        thought_signature = part["thoughtSignature"]
                        logger.debug(f"ğŸ§  æ‰¾åˆ°æ€ç»´ç­¾å: {thought_signature[:50]}...")

                    if "text" in part and isinstance(part.get("text"), str):
                        text_chunks.append(part.get("text", ""))

                    inline_data = part.get("inlineData") or part.get("inline_data")
                    if inline_data and not part.get("thought", False):
                        mime_type = (
                            inline_data.get("mimeType")
                            or inline_data.get("mime_type")
                            or "image/png"
                        )
                        base64_data = inline_data.get("data", "")

                        logger.debug(
                            f"ğŸ¯ æ‰¾åˆ°å›¾åƒæ•°æ® (å€™é€‰{idx} ç¬¬{i + 1}éƒ¨åˆ†): {mime_type}, å¤§å°: {len(base64_data)} å­—ç¬¦"
                        )

                        if base64_data:
                            image_format = (
                                mime_type.split("/")[1] if "/" in mime_type else "png"
                            )

                            logger.debug("ğŸ’¾ å¼€å§‹ä¿å­˜å›¾åƒæ–‡ä»¶...")
                            save_start = asyncio.get_event_loop().time()

                            saved_path = await save_base64_image(
                                base64_data, image_format
                            )

                            save_end = asyncio.get_event_loop().time()
                            logger.debug(
                                f"âœ… å›¾åƒä¿å­˜å®Œæˆï¼Œè€—æ—¶: {save_end - save_start:.2f}ç§’"
                            )

                            if saved_path:
                                image_paths.append(saved_path)
                                image_urls.append(saved_path)
                            else:
                                try:
                                    with tempfile.NamedTemporaryFile(
                                        prefix="gem_inline_",
                                        suffix=f".{image_format}",
                                        delete=False,
                                    ) as tmp_file:
                                        tmp_path = Path(tmp_file.name)
                                        cleaned = base64_data.strip().replace("\n", "")
                                        if ";base64," in cleaned:
                                            _, _, cleaned = cleaned.partition(
                                                ";base64,"
                                            )
                                        raw = base64.b64decode(cleaned, validate=False)
                                        tmp_file.write(raw)
                                    image_paths.append(str(tmp_path))
                                    image_urls.append(str(tmp_path))
                                    logger.debug(
                                        "âš ï¸ save_base64_image å¤±è´¥ï¼Œå·²ä½¿ç”¨å®½æ¾è§£ç å†™å…¥ä¸´æ—¶æ–‡ä»¶: %s",
                                        tmp_path,
                                    )
                                except Exception as e:
                                    logger.warning(
                                        "å€™é€‰ %s ç¬¬ %s éƒ¨åˆ† inlineData è§£ç å¤±è´¥ï¼Œè·³è¿‡ï¼š%s",
                                        idx,
                                        i + 1,
                                        e,
                                    )
                        else:
                            logger.warning(
                                f"å€™é€‰ {idx} çš„ç¬¬ {i} ä¸ªpartæœ‰inlineDataä½†dataä¸ºç©º"
                            )
                    elif "thought" in part and part.get("thought", False):
                        logger.debug(f"å€™é€‰ {idx} çš„ç¬¬ {i} ä¸ªpartæ˜¯æ€è€ƒå†…å®¹")
                    else:
                        logger.debug(
                            f"å€™é€‰ {idx} çš„ç¬¬ {i} ä¸ªpartä¸æ˜¯å›¾åƒä¹Ÿä¸æ˜¯æ€è€ƒ: {list(part.keys())}"
                        )
                except Exception as e:
                    logger.error(
                        f"å¤„ç†å€™é€‰ {idx} çš„ç¬¬ {i} ä¸ªpartæ—¶å‡ºé”™: {e}", exc_info=True
                    )

        logger.debug(f"ğŸ–¼ï¸ å…±æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")

        if text_chunks:
            extracted_urls: list[str] = []
            extracted_paths: list[str] = []
            for chunk in text_chunks:
                extracted_urls.extend(client._find_image_urls_in_text(chunk))
                urls2, paths2 = await client._extract_from_content(chunk)
                extracted_urls.extend(urls2)
                extracted_paths.extend(paths2)

            if extracted_urls or extracted_paths:
                image_urls.extend(extracted_urls)
                image_paths.extend(extracted_paths)

        text_content = (
            " ".join(chunk for chunk in text_chunks if chunk).strip()
            if text_chunks
            else None
        )
        if text_content:
            logger.debug(f"ğŸ¯ æ‰¾åˆ°æ–‡æœ¬å†…å®¹: {text_content[:100]}...")

        if not (image_paths or image_urls) and fallback_texts:
            appended = await client._append_images_from_texts(
                fallback_texts, image_urls, image_paths
            )
            if appended and not text_content:
                text_content = (
                    " ".join(t.strip() for t in fallback_texts if t and t.strip())
                    or text_content
                )

        if image_paths or image_urls:
            parse_end = asyncio.get_event_loop().time()
            logger.debug(f"ğŸ‰ APIå“åº”è§£æå®Œæˆï¼Œæ€»è€—æ—¶: {parse_end - parse_start:.2f}ç§’")
            return image_urls, image_paths, text_content, thought_signature

        if text_content:
            logger.warning("APIåªè¿”å›äº†æ–‡æœ¬å“åº”ï¼Œæœªç”Ÿæˆå›¾åƒï¼Œå°†è§¦å‘é‡è¯•")
            logger.debug(f"Googleå“åº”å†…å®¹: {str(response_data)[:1000]}")
            raise APIError(
                f"å›¾åƒç”Ÿæˆå¤±è´¥ï¼šAPIåªè¿”å›äº†æ–‡æœ¬å“åº”ï¼Œæ­£åœ¨é‡è¯•... | å“åº”é¢„è§ˆ: {str(response_data)[:300]}",
                500,
                "no_image_retry",
            )

        logger.warning(f"æœªåœ¨å“åº”ä¸­æ‰¾åˆ°å›¾åƒæ•°æ®ï¼Œå“åº”å†…å®¹: {str(response_data)[:500]}")
        raise APIError(
            f"å›¾åƒç”Ÿæˆå¤±è´¥ï¼šå“åº”æ ¼å¼å¼‚å¸¸ï¼Œæœªæ‰¾åˆ°æœ‰æ•ˆçš„å›¾åƒæ•°æ® | å“åº”: {str(response_data)[:300]}",
            None,
            "invalid_response",
        )

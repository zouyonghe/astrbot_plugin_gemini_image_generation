"""OpenAI å…¼å®¹æ¥å£ä¾›åº”å•†å®ç°ã€‚

ç”¨äºå„ç±»â€œOpenAI API å…¼å®¹â€çš„æœåŠ¡ï¼ˆä¾‹å¦‚åä»£ã€ç¬¬ä¸‰æ–¹å…¼å®¹ç½‘å…³ç­‰ï¼‰ã€‚
"""

from __future__ import annotations

import base64
import binascii
import re
import time
import urllib.parse
from pathlib import Path
from typing import Any

import aiohttp

from astrbot.api import logger

from ..api_types import APIError, ApiRequestConfig
from ..tl_utils import save_base64_image
from .base import ProviderRequest


class OpenAICompatProvider:
    name = "openai_compat"

    async def build_request(
        self, *, client: Any, config: ApiRequestConfig
    ) -> ProviderRequest:  # noqa: ANN401
        api_base = (config.api_base or "").rstrip("/")
        default_base = getattr(client, "OPENAI_API_BASE", "https://api.openai.com/v1")

        if api_base:
            base = api_base
            logger.debug(f"ä½¿ç”¨è‡ªå®šä¹‰ API Base: {base}")
        else:
            base = default_base
            logger.debug(f"ä½¿ç”¨é»˜è®¤ API Base ({config.api_type}): {base}")

        # OpenAI å…¼å®¹æ ¼å¼ï¼šè‡ªåŠ¨è¡¥é½ /v1
        if not config.api_base or base == default_base:
            url = f"{base}/chat/completions"
        elif not any(base.endswith(suffix) for suffix in ["/v1", "/v1beta"]):
            url = f"{base}/v1/chat/completions"
            logger.debug("ä¸ºOpenAIå…¼å®¹APIè‡ªåŠ¨æ·»åŠ v1å‰ç¼€")
        else:
            url = f"{base}/chat/completions"
            logger.debug("ä½¿ç”¨å·²åŒ…å«ç‰ˆæœ¬å‰ç¼€çš„OpenAIå…¼å®¹APIåœ°å€")

        payload = await self._prepare_payload(client=client, config=config)
        headers = {
            "Authorization": f"Bearer {config.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/astrbot",
            "X-Title": "AstrBot Gemini Image Advanced",
        }
        logger.debug(f"æ™ºèƒ½æ„å»ºAPI URL: {url}")
        return ProviderRequest(url=url, headers=headers, payload=payload)

    async def parse_response(
        self,
        *,
        client: Any,
        response_data: dict[str, Any],
        session: aiohttp.ClientSession,
        api_base: str | None = None,
    ) -> tuple[list[str], list[str], str | None, str | None]:  # noqa: ANN401
        return await self._parse_openai_response(
            client=client,
            response_data=response_data,
            session=session,
            api_base=api_base,
        )

    async def _handle_special_candidate_url(
        self,
        *,
        client: Any,
        session: aiohttp.ClientSession,
        candidate_url: str,
        image_urls: list[str],
        image_paths: list[str],
        api_base: str | None,
        state: dict[str, Any],
    ) -> bool:  # noqa: ANN401
        """å­ç±»é’©å­ï¼šå¤„ç†ç‰¹æ®Šå›¾ç‰‡ URLï¼ˆå¦‚ç›¸å¯¹è·¯å¾„/ä¸´æ—¶ç¼“å­˜ï¼‰ï¼Œè¿”å›æ˜¯å¦å·²å¤„ç†ã€‚"""
        return False

    def _find_additional_image_urls_in_text(self, text: str) -> list[str]:
        """å­ç±»é’©å­ï¼šä»æ–‡æœ¬ä¸­é¢å¤–æå–å›¾ç‰‡é“¾æ¥ï¼ˆé»˜è®¤ä¸æå–ï¼‰ã€‚"""
        return []

    async def _prepare_payload(
        self, *, client: Any, config: ApiRequestConfig
    ) -> dict[str, Any]:  # noqa: ANN401
        message_content: list[dict[str, Any]] = [
            {"type": "text", "text": f"Generate an image: {config.prompt}"}
        ]

        force_b64 = (
            str(getattr(config, "image_input_mode", "auto")).lower() == "force_base64"
        )

        supported_exts = {
            "jpg",
            "jpeg",
            "png",
            "webp",
            "gif",
            "bmp",
            "tif",
            "tiff",
            "heic",
            "avif",
        }

        if config.reference_images:
            processed_cache: dict[str, dict[str, Any]] = {}
            total_start = time.perf_counter()
            total_ref_count = len(config.reference_images)
            processed_ref_count = min(total_ref_count, 6)
            if total_ref_count > processed_ref_count:
                logger.info(
                    f"ğŸ“ å¼€å§‹å¤„ç† {processed_ref_count} å¼ å‚è€ƒå›¾ç‰‡ (å…±é…ç½® {total_ref_count} å¼ ï¼Œæœ€å¤šå¤„ç† 6 å¼ )..."
                )
            else:
                logger.info(f"ğŸ“ å¼€å§‹å¤„ç† {processed_ref_count} å¼ å‚è€ƒå›¾ç‰‡...")

            for idx, image_input in enumerate(config.reference_images[:6]):
                per_start = time.perf_counter()
                image_str = str(image_input).strip()
                if not image_str:
                    logger.warning(f"è·³è¿‡ç©ºç™½å‚è€ƒå›¾åƒ: idx={idx}")
                    continue

                if "&amp;" in image_str:
                    image_str = image_str.replace("&amp;", "&")

                if image_str in processed_cache:
                    logger.debug(f"å‚è€ƒå›¾åƒå‘½ä¸­ç¼“å­˜: idx={idx}")
                    message_content.append(processed_cache[image_str])
                    continue

                parsed = urllib.parse.urlparse(image_str)
                image_payload: dict[str, Any] | None = None

                try:
                    if (
                        parsed.scheme in ("http", "https")
                        and parsed.netloc
                        and not force_b64
                    ):
                        ext = Path(parsed.path).suffix.lower().lstrip(".")
                        if ext and ext not in supported_exts:
                            logger.debug(
                                "å‚è€ƒå›¾åƒURLæ‰©å±•åä¸åœ¨å¸¸è§åˆ—è¡¨: idx=%s ext=%s url=%s",
                                idx,
                                ext,
                                image_str[:80],
                            )

                        image_payload = {
                            "type": "image_url",
                            "image_url": {"url": image_str},
                        }
                        logger.info(f"ğŸ“ å›¾ç‰‡ {idx + 1}/{processed_ref_count} å·²åŠ å…¥å‘é€è¯·æ±‚ (URL)")
                        logger.debug(
                            "OpenAIå…¼å®¹APIä½¿ç”¨URLå‚è€ƒå›¾: idx=%s ext=%s url=%s",
                            idx,
                            ext or "unknown",
                            image_str[:120],
                        )

                    elif (
                        image_str.startswith("data:image/") and ";base64," in image_str
                    ):
                        header, _, data_part = image_str.partition(";base64,")
                        mime_type = header.replace("data:", "").lower()
                        try:
                            base64.b64decode(data_part, validate=True)
                        except (binascii.Error, ValueError) as e:
                            logger.warning(
                                "è·³è¿‡æ— æ•ˆçš„ data URL å‚è€ƒå›¾: idx=%s é”™è¯¯=%s", idx, e
                            )
                            mime_type = None

                        if mime_type:
                            ext = mime_type.split("/")[-1]
                            if ext and ext not in supported_exts:
                                logger.debug(
                                    "data URL å›¾ç‰‡æ ¼å¼ä¸å¸¸è§: idx=%s mime=%s",
                                    idx,
                                    mime_type,
                                )
                            image_payload = {
                                "type": "image_url",
                                "image_url": {"url": image_str},
                            }
                            logger.info(f"ğŸ“ å›¾ç‰‡ {idx + 1}/{processed_ref_count} å·²åŠ å…¥å‘é€è¯·æ±‚ (data URL)")
                            logger.debug(
                                "OpenAIå…¼å®¹APIä½¿ç”¨data URLå‚è€ƒå›¾: idx=%s mime=%s",
                                idx,
                                mime_type,
                            )

                    else:
                        mime_type, data = await client._normalize_image_input(
                            image_input, image_input_mode=config.image_input_mode
                        )
                        if not data:
                            if force_b64:
                                raise APIError(
                                    f"å‚è€ƒå›¾è½¬ base64 å¤±è´¥ï¼ˆforce_base64ï¼‰ï¼Œidx={idx}, type={type(image_input)}",
                                    None,
                                    "invalid_reference_image",
                                )
                            logger.warning(f"ğŸ“ å›¾ç‰‡ {idx + 1}/{processed_ref_count} æœªèƒ½åŠ å…¥å‘é€è¯·æ±‚ - æ— æ³•è½¬æ¢")
                            logger.debug(
                                "è·³è¿‡æ— æ³•è¯†åˆ«/è¯»å–çš„å‚è€ƒå›¾åƒ: idx=%s type=%s",
                                idx,
                                type(image_input),
                            )
                            continue

                        if not mime_type or not mime_type.startswith("image/"):
                            logger.debug(
                                "æœªæ£€æµ‹åˆ°æ˜ç¡®çš„å›¾ç‰‡ MIMEï¼Œé»˜è®¤ä½¿ç”¨ image/png: idx=%s",
                                idx,
                            )
                            mime_type = "image/png"

                        ext = mime_type.split("/")[-1]
                        if ext and ext not in supported_exts:
                            logger.debug(
                                "è§„èŒƒåŒ–åå›¾ç‰‡æ ¼å¼ä¸å¸¸è§: idx=%s mime=%s",
                                idx,
                                mime_type,
                            )

                        if force_b64:
                            cleaned = data.strip().replace("\n", "")
                            try:
                                base64.b64decode(cleaned, validate=True)
                                b64_kb = len(cleaned) * 3 // 4 // 1024
                                logger.info(f"ğŸ“ å›¾ç‰‡ {idx + 1}/{processed_ref_count} å·²åŠ å…¥å‘é€è¯·æ±‚ (base64, {b64_kb}KB)")
                            except Exception:
                                raise APIError(
                                    f"å‚è€ƒå›¾ base64 æ ¡éªŒå¤±è´¥ï¼ˆforce_base64ï¼‰ï¼Œæ¥æº: idx={idx}",
                                    None,
                                    "invalid_reference_image",
                                )
                            payload_url = f"data:{mime_type};base64,{cleaned}"
                        else:
                            payload_url = f"data:{mime_type};base64,{data}"

                        image_payload = {
                            "type": "image_url",
                            "image_url": {"url": payload_url},
                        }

                    if image_payload:
                        message_content.append(image_payload)
                        processed_cache[image_str] = image_payload
                        elapsed_ms = (time.perf_counter() - per_start) * 1000
                        logger.debug(
                            "å‚è€ƒå›¾åƒå¤„ç†å®Œæˆ: idx=%s è€—æ—¶=%.2fms æ¥æº=%s",
                            idx,
                            elapsed_ms,
                            parsed.scheme or "normalized",
                        )

                except Exception as e:
                    logger.warning(f"ğŸ“ å›¾ç‰‡ {idx + 1}/{processed_ref_count} æœªèƒ½åŠ å…¥å‘é€è¯·æ±‚ - {str(e)[:30]}")
                    logger.debug("å¤„ç†å‚è€ƒå›¾åƒæ—¶å‡ºç°å¼‚å¸¸: idx=%s err=%s", idx, e)
                    continue

            total_elapsed_ms = (time.perf_counter() - total_start) * 1000
            success_count = len(processed_cache)
            if success_count > 0:
                logger.info(f"ğŸ“ å‚è€ƒå›¾ç‰‡å¤„ç†å®Œæˆï¼š{success_count}/{processed_ref_count} å¼ å·²æˆåŠŸåŠ å…¥å‘é€è¯·æ±‚")
            else:
                # å‚è€ƒå›¾å…¨éƒ¨å¤„ç†å¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯
                raise APIError(
                    "å‚è€ƒå›¾å…¨éƒ¨å¤„ç†å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–æ ¼å¼ä¸æ”¯æŒã€‚å»ºè®®ï¼š1) æ£€æŸ¥å›¾ç‰‡é“¾æ¥æ˜¯å¦å¯è®¿é—®ï¼›2) å°è¯•é‡æ–°å‘é€å›¾ç‰‡ï¼›3) ä½¿ç”¨ Google API æ ¼å¼å¯èƒ½æœ‰æ›´å¥½çš„é”™è¯¯æç¤ºã€‚",
                    None,
                    "invalid_reference_image",
                )

        payload: dict[str, Any] = {
            "model": config.model,
            "messages": [{"role": "user", "content": message_content}],
            "max_tokens": config.max_tokens,
            "temperature": config.temperature
            if config.temperature is not None
            else 0.7,
            "modalities": ["image", "text"],
            "stream": False,
        }

        _res_key = (config.resolution_param_name or "").strip()
        resolution_key = _res_key if _res_key else "image_size"
        _aspect_key = (config.aspect_ratio_param_name or "").strip()
        aspect_ratio_key = _aspect_key if _aspect_key else "aspect_ratio"

        model_name = (config.model or "").lower()
        is_gemini_image_model = (
            "gemini-3-pro-image" in model_name
            or "gemini-3-pro-preview" in model_name
            or config.force_resolution
        )

        image_config: dict[str, Any] = {}

        if config.aspect_ratio:
            image_config[aspect_ratio_key] = config.aspect_ratio

        if is_gemini_image_model and config.resolution:
            image_config[resolution_key] = config.resolution

        if image_config:
            payload["image_config"] = image_config

        if is_gemini_image_model and config.enable_grounding:
            payload["tools"] = [{"google_search": {}}]

        return payload

    async def _parse_openai_response(
        self,
        *,
        client: Any,
        response_data: dict[str, Any],
        session: aiohttp.ClientSession,
        api_base: str | None = None,
    ) -> tuple[list[str], list[str], str | None, str | None]:  # noqa: ANN401
        image_urls: list[str] = []
        image_paths: list[str] = []
        text_content = None
        thought_signature = None
        fail_reasons: list[str] = []
        fallback_texts = client._collect_fallback_texts(response_data)
        special_state: dict[str, Any] = {}

        message: dict[str, Any] | None = None
        if "choices" in response_data and response_data["choices"]:
            choice = response_data["choices"][0]
            message = choice.get("message", {})
        else:
            message = client._coerce_basic_openai_message(response_data)

        if message:
            if "choices" not in response_data:
                logger.debug(
                    "[openai] ä½¿ç”¨éæ ‡å‡†å­—æ®µæ„é€  messageï¼Œkeys=%s",
                    list(response_data.keys())[:5],
                )
            content = message.get("content", "")

            text_chunks: list[str] = []
            image_candidates: list[str] = []
            extracted_urls: list[str] = []

            logger.debug(
                "[openai] è§£æå“åº” choicesï¼Œcontent_type=%s images_field=%s",
                type(content),
                bool(message.get("images")),
            )

            if isinstance(content, list):
                for part in content:
                    if not isinstance(part, dict):
                        continue

                    part_type = part.get("type")
                    if part_type == "text" and "text" in part:
                        text_val = str(part.get("text", ""))
                        text_chunks.append(text_val)
                        extracted_urls.extend(client._find_image_urls_in_text(text_val))
                    elif part_type == "image_url":
                        image_obj = part.get("image_url") or {}
                        if isinstance(image_obj, dict):
                            url_val = image_obj.get("url")
                            if url_val:
                                image_candidates.append(url_val)
            elif isinstance(content, str):
                text_chunks.append(content)
                extracted_urls.extend(client._find_image_urls_in_text(content))

            if message.get("images"):
                for image_item in message["images"]:
                    if not isinstance(image_item, dict):
                        continue

                    image_obj = image_item.get("image_url")
                    if isinstance(image_obj, dict):
                        url_val = image_obj.get("url")
                        if isinstance(url_val, str) and url_val:
                            image_candidates.append(url_val)
                    elif isinstance(image_obj, str) and image_obj:
                        image_candidates.append(image_obj)
                    elif isinstance(image_item.get("url"), str):
                        image_candidates.append(image_item["url"])

            if extracted_urls:
                image_candidates.extend(extracted_urls)

            if text_chunks:
                text_content = " ".join([t for t in text_chunks if t]).strip() or None

            for candidate_url in image_candidates:
                logger.debug("[openai] å¤„ç†å€™é€‰URL: %s", str(candidate_url)[:120])
                if isinstance(candidate_url, str) and candidate_url.startswith(
                    "data:image/"
                ):
                    image_url, image_path = await client._parse_data_uri(candidate_url)
                elif isinstance(candidate_url, str):
                    cleaned_candidate = (
                        candidate_url.strip()
                        .replace("&amp;", "&")
                        .rstrip(").,;")
                        .strip("'\"")
                    )
                    if not cleaned_candidate:
                        continue
                    if await self._handle_special_candidate_url(
                        client=client,
                        session=session,
                        candidate_url=cleaned_candidate,
                        image_urls=image_urls,
                        image_paths=image_paths,
                        api_base=api_base,
                        state=special_state,
                    ):
                        continue
                    if cleaned_candidate.startswith(
                        "http://"
                    ) or cleaned_candidate.startswith("https://"):
                        image_urls.append(cleaned_candidate)
                        logger.debug(
                            f"ğŸ–¼ï¸ OpenAI è¿”å›å¯ç›´æ¥è®¿é—®çš„å›¾åƒé“¾æ¥: {cleaned_candidate}"
                        )
                        continue
                    image_url, image_path = await client._download_image(
                        cleaned_candidate, session, use_cache=False
                    )
                else:
                    logger.warning(f"è·³è¿‡éå­—ç¬¦ä¸²ç±»å‹çš„å›¾åƒURL: {type(candidate_url)}")
                    continue

                if image_url or image_path:
                    if image_url:
                        image_urls.append(image_url)
                    if image_path:
                        image_paths.append(image_path)

            extracted_urls2: list[str] = []
            extracted_paths2: list[str] = []

            if isinstance(content, str):
                extracted_urls2, extracted_paths2 = await client._extract_from_content(
                    content
                )
            elif text_content:
                extracted_urls2, extracted_paths2 = await client._extract_from_content(
                    text_content
                )

            if extracted_urls2 or extracted_paths2:
                for url in extracted_urls2:
                    cleaned_url = (
                        str(url)
                        .strip()
                        .replace("&amp;", "&")
                        .rstrip(").,;")
                        .strip("'\"")
                    )
                    if not cleaned_url:
                        continue
                    if await self._handle_special_candidate_url(
                        client=client,
                        session=session,
                        candidate_url=cleaned_url,
                        image_urls=image_urls,
                        image_paths=image_paths,
                        api_base=api_base,
                        state=special_state,
                    ):
                        continue
                    if cleaned_url not in image_urls:
                        image_urls.append(cleaned_url)
                for p in extracted_paths2:
                    if p and p not in image_paths:
                        image_paths.append(p)

            if text_content:
                http_urls = client._find_image_urls_in_text(text_content)
                extra_urls = self._find_additional_image_urls_in_text(text_content)
                for url in [*http_urls, *extra_urls]:
                    cleaned_url = (
                        str(url)
                        .strip()
                        .replace("&amp;", "&")
                        .rstrip(").,;")
                        .strip("'\"")
                    )
                    if not cleaned_url:
                        continue
                    if await self._handle_special_candidate_url(
                        client=client,
                        session=session,
                        candidate_url=cleaned_url,
                        image_urls=image_urls,
                        image_paths=image_paths,
                        api_base=api_base,
                        state=special_state,
                    ):
                        continue
                    if cleaned_url not in image_urls:
                        image_urls.append(cleaned_url)

                loose_matches = re.finditer(
                    r"data:image/([a-zA-Z0-9.+-]+);base64,([-A-Za-z0-9+/=_\\s]+)",
                    text_content,
                    flags=re.IGNORECASE,
                )
                for m in loose_matches:
                    fmt = m.group(1)
                    b64_raw = m.group(2)
                    b64_clean = re.sub(r"\\s+", "", b64_raw)
                    image_path = await save_base64_image(b64_clean, fmt.lower())
                    if image_path:
                        image_urls.append(image_path)
                        image_paths.append(image_path)
                        logger.debug(
                            "[openai] æ¾æ•£æå– data URI æˆåŠŸ: fmt=%s len=%s",
                            fmt,
                            len(b64_clean),
                        )

        else:
            logger.debug("[openai] å“åº”ç¼ºå°‘å¯ç”¨çš„ message å­—æ®µï¼Œå°è¯• data/b64 è§£æ")

        if not (image_urls or image_paths) and fallback_texts:
            fallback_added = await client._append_images_from_texts(
                fallback_texts, image_urls, image_paths
            )
            if fallback_added and not text_content:
                text_content = (
                    " ".join(t.strip() for t in fallback_texts if t and t.strip())
                    or text_content
                )

        if not image_urls and not image_paths and response_data.get("data"):
            for image_item in response_data["data"]:
                if "url" in image_item:
                    image_url, image_path = await client._download_image(
                        image_item["url"], session, use_cache=False
                    )
                    if image_url:
                        image_urls.append(image_url)
                    if image_path:
                        image_paths.append(image_path)
                elif "b64_json" in image_item:
                    image_path = await save_base64_image(image_item["b64_json"], "png")
                    if image_path:
                        image_urls.append(image_path)
                        image_paths.append(image_path)

        if image_urls or image_paths:
            logger.debug(
                f"ğŸ–¼ï¸ OpenAI æ”¶é›†åˆ° {len(image_paths) or len(image_urls)} å¼ å›¾ç‰‡"
            )
            return image_urls, image_paths, text_content, thought_signature

        if text_content:
            detail = (
                f" | å‚è€ƒå›¾å¤„ç†æç¤º: {'; '.join(fail_reasons[:3])}"
                if fail_reasons
                else ""
            )
            logger.debug(
                "[openai] ä»…è¿”å›æ–‡æœ¬ï¼Œé•¿åº¦=%s é¢„è§ˆ=%s",
                len(text_content),
                text_content[:200],
            )
            logger.warning(f"OpenAIåªè¿”å›äº†æ–‡æœ¬å“åº”ï¼Œæœªç”Ÿæˆå›¾åƒï¼Œå°†è§¦å‘é‡è¯•{detail}")
            logger.debug(f"OpenAIå“åº”å†…å®¹: {str(response_data)[:1000]}")
            raise APIError(
                f"å›¾åƒç”Ÿæˆå¤±è´¥ï¼šAPIåªè¿”å›äº†æ–‡æœ¬å“åº”ï¼Œæ­£åœ¨é‡è¯•... | å“åº”é¢„è§ˆ: {str(response_data)[:300]}",
                500,
                "no_image_retry",
            )

        logger.warning(
            f"OpenAI å“åº”æ ¼å¼ä¸æ”¯æŒæˆ–æœªæ‰¾åˆ°å›¾åƒæ•°æ®ï¼Œå“åº”: {str(response_data)[:500]}"
        )
        return image_urls, image_paths, text_content, thought_signature
